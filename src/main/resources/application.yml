spring:
  application:
    name: robert

  mvc:
    async:
      request-timeout: ${SPRING_MVC_ASYNC_REQUEST-TIMEOUT:-1}

  threads:
    virtual:
      enabled: true

  docker:
    compose:
      enabled: false

management:
  info:
    build:
      enabled: true
    git:
      mode: FULL
    java:
      enabled: true
    os:
      enabled: true
  endpoint:
    health:
      show-details: ALWAYS
    metrics:
      enabled: true
    prometheus:
      enabled: true
    env:
      enabled: true
      show-values: ALWAYS
    configprops:
      enabled: true
      show-values: ALWAYS
  endpoints:
    web:
      exposure:
        include: info,health,metrics,scheduledtasks,loggers,prometheus,sbom
  tracing:
    sampling:
      probability: 1.0

app:
  allowed-extensions:
    ASPnet: "aspx,ascx,config,cs,csproj,licx,svc,webinfo"
    C: "c,h"
    Cpp: "cpp,hpp,cc,hh,cxx,hxx"
    Csharp: "cs"
    Dart: "dart"
    Fsharp: "fs,fsi,fsx,fsscript"
    Fortran: "f,for,f90,f95,f03"
    Erlang: "erl,hrl"
    Go: "go,mod"
    Groovy: "groovy,gvy,gy,gsh"
    Haskell: "hs,lhs"
    Java: "java,jsp,jspx"
    Julia: "jl"
    JavaScript: "js,jsx,mjs"
    Kotlin: "kt,kts"
    Markup: "md"
    MATLAB: "m,mat"
    ObjectiveC: "m,mm"
    Pascal: "pas"
    Perl: "pl,pm,t"
    PHP: "php,inc,class,phtml"
    Python: "py,pyc,pyd,pyo,pyw,pyx"
    R: "r,R"
    Ruby: "rb,rbx,rake,gemspec"
    Rust: "rs,rlib"
    Scala: "scala,sc"
    SQL: "sql,ddl"
    Swift: "swift"
    TypeScript: "ts,tsx"
    VBnet: "vb,vbproj,vbhtml"
    YAML: "yaml,yml"

---

spring:
  config:
    activate:
      on-profile: groq-cloud
    import: "optional:file:./config/creds.yml"

  ai:
    openai:
      base_url: ${OPENAI_BASE_URL:https://api.groq.com/openai}
      chat:
        options:
          model: ${CHAT_MODEL:llama-3.1-70b-versatile}
      embedding:
        options:
          model: ${EMBEDDING_MODEL:text-embedding-3-large}

---

spring:
  config:
    activate:
      on-profile: openai
    import: "optional:file:./config/creds.yml"

  ai:
    openai:
      chat:
        options:
          model: ${CHAT_MODEL:gpt-4o-mini}
      embedding:
        options:
          model: ${EMBEDDING_MODEL:text-embedding-3-large}

---

spring:
  config:
    activate:
      on-profile: ollama

  autoconfigure:
    exclude: org.springframework.ai.autoconfigure.openai.OpenAiAutoConfiguration

  ai:
    ollama:
      base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: ${CHAT_MODEL:mistral}
          num-ctx: ${CHAT_MODEL_CONTEXT_LENGTH:32768}
          truncate: false
      embedding:
        options:
          model: ${EMBEDDING_MODEL:nomic-embed-text}

---

spring:
  config:
    activate:
      on-profile: docker

  docker:
    compose:
      enabled: true
      lifecycle-management: start-and-stop
      stop:
        command: down
        arguments: -v
      timeout: 1m

---

spring:
  config:
    activate:
      on-profile: chroma

  ai:
    vectorstore:
      chroma:
        initialize-schema: true

  docker:
    compose:
      file: ./docker-compose.chroma.yml

---

spring:
  config:
    activate:
      on-profile: pgvector

  datasource:
    driver-class-name: ${SPRING_DATASOURCE_DRIVER_CLASS_NAME:org.postgresql.Driver}
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/postgres}
    username: ${SPRING_DATASOURCE_USER:postgres}
    password: ${SPRING_DATASOURCE_PASSWORD:postgres}

  ai:
    vectorstore:
      pgvector:
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimensions: ${SPRING_AI_VECTORSTORE_PGVECTOR_DIMENSIONS:768}


  docker:
    compose:
      file: ./docker-compose.pgvector.yml

---

spring:
  config:
    activate:
      on-profile: dev

  ai:
    vectorstore:
      pgvector:
        remove-existing-vector-store-table: true

debug: true

management:
  endpoints:
    web:
      exposure:
        include: "*"

logging:
  level:
    org.cftoolsuite: TRACE
